{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business goal\n",
    "This an app to predict if someone make more or less than 50k/year using different features. This app can be used when that information is not available or is confidential during a loan application at any financial institution or car financing application to have a better financial picture of the applicant. In this notebook, a classification model with a precision > 80% is the goal.\n",
    "\n",
    "Table of contents\n",
    "0 Import the libraries\n",
    "1 Get the data\n",
    "1.1 Import csv file\n",
    "1.2 Split the data into training and test sets, creating a copy of the datasets\n",
    "2.1 Quick glance at the data\n",
    "2.2 Pandas Profiling\n",
    "2.3 Univariate analysis\n",
    "2.3.1 Age\n",
    "2.3.2 Workclass\n",
    "2.3.3 Final weight\n",
    "2.3.4 Education\n",
    "2.3.5 Education-number\n",
    "2.3.6 Marital-Status\n",
    "2.3.7 Occupation\n",
    "2.3.8 Relationship\n",
    "2.3.9 Race\n",
    "2.3.10 Gender\n",
    "2.3.11 Capital gain\n",
    "2.3.12 Capital loss\n",
    "2.3.13 Hours per week\n",
    "2.3.14 Native country\n",
    "2.3.15 Income > 50K (Target variable)\n",
    "2.4 Bi-variate analysis\n",
    "2.4.1 Scatter plots\n",
    "2.4.2 Age vs hours per week (Numerical vs Numerical feature)\n",
    "2.4.3 Age vs educational number (Numerical vs Numerical feature)\n",
    "2.4.4 Educational number vs hours per week (Numerical vs Numerical feature)\n",
    "2.4.5 Educational number vs age (Numerical vs Numerical feature)\n",
    "2.4.6 Chi2 test for all the the categorical features (Categorical vs Categorical feature)\n",
    "2.4.7 ANOVA test of age vs the rest of categorical features (Numerical vs continuous feature)\n",
    "2.4.8 Heatmap\n",
    "3 Prepare the data\n",
    "3.1 Transform to be done on each feature\n",
    "3.2 Identify extra data that would be useful\n",
    "3.3 Remove outliers\n",
    "3.4 Fix the missing values\n",
    "3.5 Fix skewness\n",
    "3.6 Oversampling with SMOTE\n",
    "3.7 Data preprocessing\n",
    "4 Short-list promising models\n",
    "4.1 Functions to evaluate the models and all the metrics\n",
    "4.2 Quick models comparison\n",
    "4.3 Drop least predictive features\n",
    "4.4. Shortlist the top five models\n",
    "5 Fine-Tune the top five models\n",
    "5.1 Random forest\n",
    "5.2 Neural network\n",
    "5.3 KNN\n",
    "5.4 Gradient boosting\n",
    "5.5 Baggining\n",
    "5.6 Winner\n",
    "6 Test the performance of the model on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "from pandas_profiling import ProfileReport\n",
    "from pathlib import Path\n",
    "from scipy.stats import probplot, chi2_contingency, chi2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier, ExtraTreesClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import streamlit as st\n",
    "from scipy.stats import norm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the data\n",
    "1.1 Import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../Credit-Card-Transactions-Fraud-Detection-Cat/fraudTrain.csv')\n",
    "test_data = pd.read_csv('../Credit-Card-Transactions-Fraud-Detection-Cat/fraudTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat([train_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Split the data into training and test sets, creating a copy of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "def data_split(df, test_size):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_split(full_data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate = train_data.duplicate()\n",
    "test_duplicate = test_data.duplicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the data\n",
    "2.1 Quick glance at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(train_duplicate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(train_duplicate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_report = ProfileReport(train_duplicate, explorative=True, dark_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_report_folder = Path('pandas_profile_folder/Credit_Card_Transctions_Fraud_profile.html')\n",
    "\n",
    "try:\n",
    "    profile_report_folder.resolve(strict=True)\n",
    "except FileNotFoundError:\n",
    "    profile_report.to_folder(\"pandas_profile_folder/Credit_Card_Transctions_Fraud_profile.html\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that will return the value count and frequency of each observation within a column\n",
    "def value_cnt_norm_cal(df,feature):\n",
    "    ftr_value_cnt = df[feature].value_counts()\n",
    "    ftr_value_cnt_norm = df[feature].value_counts(normalize=True) * 100\n",
    "    ftr_value_cnt_concat = pd.concat([ftr_value_cnt, ftr_value_cnt_norm], axis=1)\n",
    "    ftr_value_cnt_concat.columns = ['Count', 'Frequency (%)']\n",
    "    return ftr_value_cnt_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate['age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate['age'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_duplicate['age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_value_cnt_norm = train_duplicate['age'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_value_cnt = train_duplicate['age'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
